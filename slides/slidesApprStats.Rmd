---
title: "Projet apprentissage statistiques - Etude SpeedDating"
author: "Florian JACTA, Hugo MICCINILLI, Theo DI PIAZZA, Aboa BOUADOU, Linh NGUYEN"
date: '2021'
output:
  ioslides_presentation: default
  theme: league
  beamer_presentation: default
  slidy_presentation: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Description du problème et des données
## Description du problème

* L'amour : Comment mettre en relation les personnes qui ont le plus le chance de s'aimer ?

* Données issues de SpeedDating

<center>
  <img src="img/speed_dat_img.jpg" style="vertical-align: middle;" width = "600"/>
</center>

## Table des matières

* Présentation du jeu de données
* Preprocessing & Nettoyage
* Visualisation et Statistiques Descriptives
* Les modèles
* Le modèle retenu et conclusion

## Présentation de la base de données

* Base de données recupérée sur [kaggle](https://www.kaggle.com/annavictoria/speed-dating-experiment) 
* Données brutes : 
    + 8379 lignes et 195 variables
    + variable à expliquer : match
    + Variables explicatives : 73 variables de type identification

<center>
  <img src="img/resume_projet.jpg" style="vertical-align: middle;" width = "500"/>
</center>

## Presentation de la base de données    
* Variable à expliquer *match* : 84% de 0 (pas de match entre le couple) et 16% de 1 (match) ---> données déséquilibrées
    

```{r echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
library(tidyverse)
df_speed=read.csv("../DataBase/Speed Dating Data.csv")
ggplot(df_speed, aes(x = match)) +  
  geom_bar(aes(y = (..count..)/sum(..count..)))
```

## Preprocessing 

<h1> Nettoyage du jeu de données </h1>

* Gerer les problemes de codage
* Harmonser le système de points
* Gestion des valeurs manquantes 
* Suppresion de variables inutilisables pour répondre à la problématique
* Joindre les inforations

<h1> Création de nouvelles variables </h1>
* Aggréger certaines modalités des variables qualitatives
* Variable comptage
* Variables représentant la distances entre les partenaires


# Présentation et visualisation des donnees

## Présentation

* Une ligne correspond aux données de 2 individus
* Variable à expliquer *match* : 84% de 0 (pas de match entre le couple) et 16% de 1 (match) ---> données déséquilibrées
* Différents types de variables caractérisant :
    + comment les individus s'évaluent eux même (attractivité, intelligence, etc...) 
    + ce que les individus recherchent chez leur potentiel partenaire
    + centres d'intérêts des individus (cinéma, sport, etc...)


## Visualisation & Statistiques descriptives

* Corrélation : Les activités pratiquées par les femmes
<center>
  <img src="img/cor1.png" style="vertical-align: middle;" width = "500"/>
</center>

## Visualisation & Statistiques descriptives

* Corrélation : Les activités pratiquées par les hommes
<center>
  <img src="img/cor2.png" style="vertical-align: middle;" width = "500"/>
</center>

## Visualisation & Statistiques descriptives

* Corrélation : Ce que les personnes du même sexe qu'elle recherche
<center>
  <img src="img/cor3.png" style="vertical-align: middle;" width = "500"/>
</center>

## Visualisation & Statistiques descriptives

* Corrélation : Rapport de corrélation entre les variables quantitatives et la variable réponse
<center>
  <img src="img/rapp_cor.png" style="vertical-align: middle;" width = "700"/>
</center>

## Visualisation & Statistiques descriptives

* Significativité : Test de Student pour chaque variable quantitative et la variable réponse
<center>
  <img src="img/student_test.png" style="vertical-align: middle;" width = "700"/>
</center>

## Visualisation & Statistiques descriptives

* Corrélation : V de Cramer pour chaque variable qualitative avec la variable réponse
<center>
  <img src="img/Vcramer.png" style="vertical-align: middle;" width = "700"/>
</center>



# Critères de performance
## Critères de performance
* Données déséquilibrées : 84% d'exactitude en prédisant que des 0 
* Mettre l'accent sur le taux de match détecté :
    + Precision, Sensibilité et F1-Score
    + Ne pas négliger la performance globale

## Critères de performance
<center>
  <img src="img/precision-rappel.png" style="vertical-align: middle;"/>
</center>

# Régression Logistique (Modèle 1/5)
## Régression Logistique

* Modèle "naturel" pour une classification binaire
* 100+ variables --> fléau de la dimension
* Reduction du nombre de variables avec **caret**
<center>
  <img src="img/sbf.png" style="vertical-align: middle;" width = "700"/>
</center>
* Passage de 100+ variables à 44 variables

## Premier résultat

<center>
  <img src="img/reglog1.png" style="vertical-align: middle;" width = "700"/>
</center>

* Mauvaise performance au vu de nos critères
* Hypothèse : cela est du au déséquilibre des données

## Suréchantillonage (Oversampling)

* Randomly Over Sampling Examples (ROSE) : equilibrage des données
* "Nouvelle" base d'apprentissage
* Ajustement d'un nouveau modèle et meilleurs résultats

## Résultats

![](img/reglog21.png){width=50%}--![](img/reglog22.png){width=40% height="310ps"}

* Regression Logistique normale inadaptée



# Régression de Lasso : 4 modèles (Modèle 2/5)
## Régression de Lasso : Sans sampling

* Optimisation de l'hyper-paramètre Lambda
<center>
  <img src="img/reg_norm.png" style="vertical-align: left;" width = "700"/>
</center>

## Régression de Lasso : Sans sampling

* Résultats obtenus
<center>
  <img src="img/reg_norm_res.png" style="vertical-align: left;" width = "400"/>
</center>

## Régression de Lasso : Avec Rose

* Optimisation de l'hyper-paramètre Lambda
<center>
  <img src="img/reg_norm.png" style="vertical-align: left;" width = "700"/>
</center>

## Régression de Lasso : Avec Rose

* Résultats obtenus
<center>
  <img src="img/reg_rose_res.png" style="vertical-align: left;" width = "400"/>
</center>

## Régression de Lasso : Avec Over-Sampling

* Optimisation de l'hyper-paramètre Lambda
<center>
  <img src="img/reg_over.png" style="vertical-align: left;" width = "700"/>
</center>

## Régression de Lasso : Avec Over-Sampling

* Résultats obtenus
<center>
  <img src="img/reg_over_res.png" style="vertical-align: left;" width = "400"/>
</center>

## Régression de Lasso : Avec Under-Sampling

* Optimisation de l'hyper-paramètre Lambda
<center>
  <img src="img/reg_under.png" style="vertical-align: left;" width = "700"/>
</center>

## Régression de Lasso : Avec Under-Sampling

* Résultats obtenus
<center>
  <img src="img/reg_under_res.png" style="vertical-align: left;" width = "400"/>
</center>

## Régression avec Lasso : Résumé des scores

* Tableau des scores pour différents sampling
<center>
  <img src="img/lasso_resume_scores.png" style="vertical-align: left;" width = "700"/>
</center>

# SVM (Modèle 3/5)
## SVM

* 100+ variables --> cas des données non-séparables

## Premier modèle

* Modèle SVM linéaire sur la base initiale

<center>
  <img src="img/svm-lin-simple.png" style="vertical-align: middle;" width = "300"/>
</center>

* Mauvais modèle qui classifie tous comme des couples non match parce que cela donne un taux 83.4% des couples correctement prédites    

---> Due au déséquilibre dans la base de données 

* Solution : Surechantillonage de ROSE

## Les modèles obtenus avec la nouvelle base de données d'apprentissage avec ROSE

* Modèles testés : SVM linéaire, SVM radial, SVM polynomial.

* Pour chaque modèle, on retire la précision, la sensibilité et le F1 score pour les comparer à la fin.

## SVM linéaire
* Séparation des données par un seuil linéaire
* <span class="red2">**Pénalisation**</span> de la mauvaise classification
* <span class="red2">**Cout**</span> de pénalisation à calibrer

<left>
  <img src="img/SVM-lin-rose.png" style="vertical-align: middle;" width="280"/>
</left>
<right>
  <img src="img/svm_lin_rose.png" style="vertical-align: middle;" width="280"/>
</right>

**Meilleur modèle** : <span class="red2"> Cout = 0.1 </span>

## SVM radial
* Séparation des données par un seuil radial
* <span class="red2">**Cout**</span> de pénalisation à calibrer

<left>
  <img src="img/SVM-rad-rose.png" style="vertical-align: middle;" width="280"/>
</left>
<right>
  <img src="img/SVM-rad-rose-optim-param.png" style="vertical-align: middle;" width="280"/>
</right>

**Meilleur modèle** : <span class="red2"> Cout = 0.1, Gamma = 0.01  </span>

## SVM polynomial
* Séparation des données par un seuil polynomial
* <span class="red2">**Cout**</span> de pénalisation à calibrer
* <span class="red2">**Degrès**</span> du polynome à calibrer

<left>
  <img src="img/SVM-pol-rose.png" style="vertical-align: middle;" width="280"/>
</left>
<right>
  <img src="img/SVM-pol-rose-optim-param.png" style="vertical-align: middle;" width="280"/>
</right>


**Meilleur modèle** : <span class="red2"> Cout = 0.1, Degree = 3 </span>

## Comparaison des 3 modèles

<center>
  <img src="img/comparaison.png" style="vertical-align: middle;" width="780"/>
</center>

**Meilleur modèle** : SVM polynomial de degré 3 avec le cout égal à 0.1


# XGBOOST (Modèle 4/5)

## XGBOOST
Les hyperparamètres à optimiser sont :
<ul>
<li> le nombre d'itération du boosting</li>
<li>la profondeur maximale des arbres </li>
<li>le pas de descente de gradient</li>
<li>le pourcentage de variable qu'on garde pour la construton de chaque arbre</li>
<li>la taille des sous-échantillons</li>
<li>le gain minimum pour diviser un noeud</li>
</ul>

## XGBOOST Evaluation
<div class='row' style="display: flex">
<div class="col-sm-6">
  <img src="img/xgboost_prec_rappel.png" width="100%" title="jjjj"/>
  <h3>Précision rappel</h3>
</div>
<div class="col-sm-6">
  <img src="img/xgboost_f1.png" width="100%"/>
  <h3>F1-score en fonction du seuil</h3>
  </div>
</div>
## XGBOOST Matrice de confusion

<div class='row' style="display: flex">
<div class="col-sm-4">
  <img src="img/matrix_xgboost.png" width="100%"/>
  <h3>Xgboost</h3>
</div>
<div class="col-sm-3">
  <img src="img/matrix_xgboost_up.png" width="100%"/>
   <h4>Xgboost<br> sur-échantillonnage</h4>
  </div>
<div class="col-sm-3">
  <img src="img/matrix_xgboost_down.png" width="100%"/>
   <h4>Xgboost <br>sous-échantillonnage</h4>
  </div>
</div>



# Intelligence artificielle (Modèle 5/5)
## Intelligence artificielle

* Réseaux de neurones : neurones d'entrées et de sortie
* Couches de neurones cachées
* Fonction d'activation
* Fonction de coût

<center>
  <img src="img/reseau.jpg" style="vertical-align: middle;" width = "500"/>
</center>


## Méthode : Fonction de perte "focal loss"


* Déséquilibre > trouver une fonction de perte adéquate
* Fonction de perte : "focal loss"
* Voici la formule pour cette fonction de perte :

<center>
  <img src="img/Focal_loss.png" style="vertical-align: middle;" width = "300"/>
</center>

Hyperparamètres : ${\gamma}$

    
## Méthode : Fonction de perte "focal loss"

* Architecture :
  + 3 couches (139, 97, 42)
  + Fonction d'activation : sigmoid
  + Fonction de perte : focal loss
  + gamma = 2

## Méthode : Fonction de perte "focal loss"


<center>
  <img src="img/Perf_focal.png" style="vertical-align: middle;" width = "300"/>
</center>*

## Méthode : poids

* Fonction de perte instable > autre solution
* Mettre des différents poids sur les classes
* Formule pour les poids :
    + nombre de la plus grande classe/nombre de la classe i
* Hyperparamètres classique d'IA
* Architecture : 
  + 3 couches (88, 16, 16)
  + Fonction d'activation : sigmoid
  + Fonction de perte : Binary crossentropy

## Méthode : poids

* F1_Score seuil 0.5 :  0.358
* F1_score meilleur seuil : 0.363

<center>
  <img src="img/Perf_poids.png" style="vertical-align: middle;" width = "300"/>
</center>

## Méthode ROSE

* Autres méthodes ? Rééchantillonage ROSE
* Avantage : retomber sur un cas classique d'un problème équilibré
* Architecture :
  + 3 couches (139, 97, 42)
  + Fonction d'activation : sigmoid
  + Fonction de perte : Binary crossentropy


## Méthode ROSE

* F1_Score seuil 0.5 : 0.38
* F1_score meilleur seuil : 0.395

<center>
  <img src="img/Perf_rose.png" style="vertical-align: middle;" width = "300"/>
</center>

## Méthode suréchantillonage

* Rééchantillonage : oversampling
* Architecture :
  + 3 couches cachées (111, 70, 21)
  + Fonction d'activation : sigmoid
  + Fonction de perte : Binary crossentropy
  
## Méthode suréchantillonage

* F1_Score seuil 0.5 : 0.38
* F1_score meilleur seuil : 0.384

<center>
  <img src="img/Perf_over.png" style="vertical-align: middle;" width = "300"/>
</center>

# Comparaison des algos
## Comparaison des algos


<br/>
<br/>
<br/>


<center>
  <img src="img/tableau_comparaison.png" style="vertical-align: middle;" width = "800"/>
</center>

## Quelques mots pour comparer les algos

* Essai de combinaisaon des modèles entre IA et XGBoost
  + Vote à la majorité avec pondération et choix des meilleurs score pour maximiser le F1_score

<center>
  <img src="img/Combination_modele.png" style="vertical-align: middle;" width = "300"/>
</center>

# Conclusion
## Conclusion
